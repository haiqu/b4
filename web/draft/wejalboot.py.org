#+title: wejal bootstrap


* Strategy
:PROPERTIES:
:TS:       <2015-01-18 10:25AM>
:ID:       nrogjy71jqg0
:END:

The idea here is to manually construct a data structure (an abstract syntax tree) that describes a meta-grammar.

The meta-grammar describes whatever nice clean syntax we'd /like/ to use for creating grammars in the future.

Building these trees by hand can get messy, though, so we'll stick with a simple syntax for this first round, and then use /that/ to implement something better later.

Our first step is to define some types that we can use to tag the different parts of the tree. Each type represents the some feature of our pattern matching system.

* Some data types for modeling grammar definitions.
:PROPERTIES:
:TS:       <2015-01-18 07:56AM>
:ID:       9906u111jqg0
:END:
#+name: @imports
#+begin_src python :session :results none
  from collections import namedtuple
#+end_src
#+name: @code
#+begin_src python :session :results none
  def T(tag, doc, args):
      """Creates a new tuple type."""
      res = namedtuple(tag, args)
      if doc: res.__doc__+=' : '+doc
      return res

  def TB(tag, doc, args=['body']): return T(tag, doc, args)
  def TI(tag, doc, args=['item']): return T(tag, doc, args)
  def TN(tag, doc, args=['name']): return T(tag, doc, args)
  def T2(tag, doc, args=['name','body']): return T(tag, doc, args)

  Gram = T('Gram', 'contains grammar rules (may inherit from `base`).',
           ['name', 'base', 'doc', 'body'])
  Def = T('Def', 'define a named rule.', ['name','body'])
  Ref = TN('Ref', 'refer to (invoke) a named rule')

  Any = T('Any', 'match anything', [])
  Not = TI('Not', 'fail if the pattern would match, but do not consume')
  Skip = TI('Skip', 'match the pattern, but hide it from other rules')

  Lit = TI('Lit', 'match literal item (using ==)')
  Seq = TB('Seq', 'match a sequence of patterns')
  Grp = TB('Grp', 'same as Seq, but renders in parentheses')
  Alt = TB('Alt', 'match any of the alternatives')
  Rep = TI('Rep', 'match 1 or more repetitions.')
  Opt = TI('Opt', 'match 0 or 1 repetitions.')
  Orp = TI('Orp', 'match 0 or more repetitions.')

  Var = T2('Var', 'save matched string in a variable.')
  Val = TN('Val', 'match against the saved value.')
  New = T2('New', 'build a new class/tuple instance')
  Arg = TB('Arg', 'pass matched data as arg to containing "New"')

#+end_src

* Manually build a base grammar to provide generic tokenization.
:PROPERTIES:
:TS:       <2015-01-18 10:10AM>
:ID:       9d0f2971jqg0
:END:
#+name: @imports
#+begin_src python :session :results none
  import string
#+end_src
#+name: @code
#+begin_src python :session :results none
  ECHR, SQ, DQ = ['\\', "'", '"']
  base = Gram('ebnf', [], "rules common to all grammars", [
      Def('main', Orp('token')),
      Def('token',Seq([Skip(Orp(Ref('space'))),
                    Alt([Ref('STRING'), Ref('NUMBER'),
                         Ref('IDENT'), Ref('DELIM'),
                         Rep(Not(Ref('space')))])])),
      Def('space', Orp('White')),
      # character classes:
      Def('White', Alt([chr(c) for c in range(33)])),
      Def('Upper', Alt(list(string.ascii_uppercase))),
      Def('Lower', Alt(list(string.ascii_lowercase))),
      Def('Alpha', Alt([Ref('Lower'), Ref('Upper')])),
      Def('Under', Lit('_')),
      Def('Neg', Lit('-')),
      Def('Digit', Alt([Lit(c) for c in string.digits])),
      Def('Hexit', Alt([Ref('Digit')]+[Lit(c) for c in 'abcdefABCDEF'])),
      Def('Alnum', Alt([Ref('Under'), Ref('Alpha'), Ref('Digit')])),
      # simple patterns:
      Def('IDENT', Seq([Alt([Ref('Under'),Ref('Alpha')]), Orp(Ref('Alnum'))])),
      Def('NUMBER',Seq([Opt(Ref('Neg')), Rep(Ref('Digit')),
                     Orp([Ref('Under'),
                          Ref('Digit'),Ref('Digit'),Ref('Digit')])])),
      Def('STRING', Alt([Seq([Lit(DQ), Rep(Ref('STRCHR')), Lit(DQ)])])),
      Def('STRCHR', Alt([Seq([Lit(ECHR), Alt([ Lit(ECHR), Lit(DQ) ])]),
                         Not(DQ) ])),
      Def('DELIM', Alt(list('(){}[]'))),
  ])
#+end_src

* Now define the bootstrap grammar to parse EBNF grammar definitions.
:PROPERTIES:
:TS:       <2015-01-18 08:27AM>
:ID:       7o9j7i21jqg0
:END:

#+name: @code
#+begin_src python :session :results none
  ebnf = Gram('ebnf', [base], "ebnf meta-grammar (for parsing grammars)", [
      Def('main', Orp(Ref('rule'))),
      Def('rule', Seq([Var('name', Ref('IDENT')),
                       Lit('='), Ref('expr'), Lit('.') ])),
      Def('expr', Seq([ Ref('term'), Orp([Lit('|'), Ref('term') ]) ])),
      Def('term', Seq([ Ref('factor'), Rep(Ref('factor')) ])),
      Def('factor', Alt([Ref('IDENT'), Ref('STRING'),
                         Ref('rep'), Ref('opt'), Ref('grp')])),
      Def('rep', Seq([Lit('{'), New(Rep, Ref('expr')), Lit('}')])),  # 'x*'
      Def('opt', Seq([Lit('['), New(Opt, Ref('expr')), Lit(']')])),  # 'x?'
      Def('grp', Seq([Lit('('), New(Grp, Ref('expr')), Lit(')')])),  # '(x)'
  ])
#+end_src

* Generic dispatch:
:PROPERTIES:
:TS:       <2015-01-18 11:36AM>
:ID:       w0bhd8b1jqg0
:END:
We need a way walk these trees and dispatch to an appropriate method for each type of node in our AST.

#+name: @imports
#+begin_src python :sesson :results none
from warnings import warn
#+end_src

#+name: @code
#+begin_src python :session :results none

  class Dispatcher(object):
      def __init__(self, tree):
          self.root = tree
          self.done = False
          self.node = None
          self.path = [] # stack of breadcrumbs from the root

      def walk(self, prefix, node):
          meth_name = "%s_%s" % (prefix, node.__class__.__name__)
          if hasattr(self, meth_name):
              return getattr(self, meth_name)(node)
          else: warn('no handler for %s' % (meth_name))

#+end_src

* Worlds for backtracking.
:PROPERTIES:
:TS:       <2015-01-18 12:59PM>
:ID:       u8s6vh00kqg0
:END:

A world is a context for holding changes, similar to a working copy in a version control system. The idea is that any time we might need to backtrack (any time an =Alt= node is encountered), we'll fork a new world, and changes we make are done to the world object. This way, if the match ultimately fails, we can rewind the side effects.

This ability is common in prototype-based langugaes like Self and JavaScript (though it isn't necessarily commonly /used/). The name 'World' and the idea of applying it to parsing comes from Alex Warth's [[http://www.tinlizzie.org/ometa/][OMeta]] dissertation.

It's easy to make a python class that works this way: we just override =__getattr__= (for the =x.a= syntax), and =__getitem__= (for the =x[a]= syntax) so that they delegate to a prototype object when there's no local value defined.

Since we do /not/ override the corresponding =__setitem__= and =__setattr__= methods, any assignment made to an attribute or item of the world will affect the local object, leaving the prototype's value unchanged.

It's very much like what happens when overriding methods in a subclass, except it happens for individual objects rather than classes, and it happens dynamically at runtime.

#+name: @code
#+begin_src python :session :results none

  HOME = {} # arbitrary dictionary object

  class World(dict):

      def __init__(self, proto=HOME):
          super(World, self).__init__()
          self.proto = proto

      def __getattr__(self, name):
          # called when attribute has no local definition.
          return getattr(self.proto, name)

      def __getitem__(self, key):
          if key in self.keys(): return super(World, self)[key]
          else: return self.proto[key]

      def changed(self, key, val):
          """Forks a new world, with one key changed."""
          res = World(self)
          res[key] = val
          return res

#+end_src

* Grammar Interpreter
:PROPERTIES:
:TS:       <2015-01-18 12:28PM>
:ID:       n0pcnnd1jqg0
:END:

We will assume for now that we have the entire string in memory.

#+name: @code
#+begin_src python :session :results none

  class Grin(Dispatcher):
      """Grammar Interpreter"""

      def __init__(self, root):
          super(Grin,self).__init__(root)
          self.init(root)

      def parse(self, src):
          self.env = World()
          self.src, self.pos, self.ch = src, 0, ''
          self.page, self.line, self.col = 0, 0, 0

      <<@methods>>
#+end_src

* ebnf in ebnf
:PROPERTIES:
:TS:       <2015-01-18 12:51PM>
:ID:       bd6hv400kqg0
:END:
Here's an grammar for EBNF written in EBNF, so we can test the parser.

This text is adapted from [[http://www.inf.ethz.ch/personal/wirth/CompilerConstruction/index.html][Compiler Construction]] by Niklaus Wirth (who invented EBNF, as well as Pascal, Modula, Oberon, and a variety of other languages).

#+name: ebnf
#+begin_src prolog
main = { rule } .
rule = IDENT "=" expr "." .
expr = term { "|" term } .
term = factor { factor } .
factor = IDENT | STRING | "{" expr "}" | "[" expr "]" | "(" expr ")" .
#+end_src

I placed that code in a block of its own so it would be syntax highlighted, but for python it should be inside a string.

#+name: @code
#+begin_src python :session :results none
ebnf_src = '''\
<<ebnf>>
'''
#+end_src

* OUTPUT wejalboot.py
:PROPERTIES:
:TS:       <2015-01-18 12:38PM>
:ID:       npdbb4e1jqg0
:END:

And now we can put the whole thing together:

#+begin_src python :session :tangle "wejalboot.py" :noweb yes
  <<@imports>>
  <<@code>>
  if __name__=="__main__":
      print(Grin(ebnf).parse(ebnf_src))
#+end_src

If we try to run this now, here's what we'll get:

#+begin_src org
=wejalboot.py:92:= *UserWarning: no handler for init_Gram*
  ~yield warn('no handler for tag: %s' % node.__class__.__name__)~
/None/
#+end_src

So now our job is to go back and fill in a handler method for each node until it's able to walk the whole tree.

* TODO Input cursor
:PROPERTIES:
:TS:       <2015-01-22 05:51AM>
:ID:       m3udu291oqg0
:END:

Traditionally, in functional languages, strings are represented as a linked list of characters, which makes them easy to work with recursively.

#+name: @code
#+begin_src python :session :results none
  class StringCursor(object):

      def __init__(self, aString:str):
          self.string = s
          self.pos = -1
          self.line= 0
          self.fwd()

      def fwd(self):
          self.pos += 1
          self.ch

#+end_src

* Data structure for parse results.
:PROPERTIES:
:TS:       <2015-01-22 05:58AM>
:ID:       x88gff91oqg0
:END:

The output format will be almost the same as the input format.

#+name: @code
#+begin_src python :session :results none
  class Fail(object): """Value to indicate failure."""
  FAIL = Fail()
#+end_src

* Inference Rules
:PROPERTIES:
:TS:       <2015-01-22 06:01AM>
:ID:       yg99mk91oqg0
:END:

These were translated from the sequent notation in Warth's Ometa paper.

#+name: @methods
#+begin_src python :session :results none

  # (inside  `class Grin`...)

  def match_Ref(self, node, cur, env):
      # pass in fresh World, then discard changes
      tup = self.match(self.defs[node.name], cur, World())
      if tup[0] is FAIL: return (FAIL, env)
      else: return (tup[0], tup[1], env)

  def match_Emp(self, node, cur, env):
      return (None, cur, env)

  def match_Lit(self, node, cur, env):
      if cur.value == node.item: return (cur.value, cur.fwd(), env)
      else: return (FAIL, cur, env)

  def match_Seq(self, node, cur, env):
      for item in node.body:
          tup = self.match(item, cur, env)
          if tup[0] is FAIL: return (FAIL, tup[1])
          else: val, cur, env = tup
      return tup # last value

  def match_Alt(self, node, cur, env):
      for item in node.body:
          tup = self.match(item, cur, env)
          if tup[0] is FAIL: env = tup[1]
          else: return tup
      return tup # last failure

  def match_Orp(self, node, cur, env):
      vals = []
      while True:
          tup = self.match(node.item, cur, env)
          if tup[0] is FAIL: break
          else:
              val, cur, env = tup
              vals.append(val)
      return (vals, cur, env)

  def match_Not(self, node, cur, env):
      tup = self.match(node.item, cur, env)
      if tup[0] is FAIL: return (None, cur, tup[1])
      else: return (FAIL, tup[1])

  def match_Var(self, node, cur, env):
      tup = self.match(node.item, cur, env)
      if tup[0] is FAIL: return tup
      else: return (tup[0], cur, env.changed(node.name, tup[0]))

  def match_Act(self, node, cur, env):
      raise NotImplementedError('no semantic actions yet.')

  def match_Box(self, node, cur, env):
      raise NotImplementedError('no tree matching yet.')

#+end_src

* Compilation step.
:PROPERTIES:
:TS:       <2015-01-18 02:10PM>
:ID:       ks01bt30kqg0
:END:

#+name: @methods
#+begin_src python :session :results none

  # (still inside  `class Grin`...)
  def init(self, node):
      return self.walk('init', node)

  def init_Gram(self, node):
      self.defs = {}
      for child in node.body: self.init(child)

  def init_Def(self, node):
      self.defs[node.name] = node

#+end_src

* TODO credits
:PROPERTIES:
:TS:       <2015-01-22 08:13AM>
:ID:       hnv0l310pqg0
:END:
- grammar rules are adapted from Alessandro Warth's [[http://tinlizzie.org/ometa/][Ometa]] system.
