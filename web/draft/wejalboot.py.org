#+title: wejal bootstrap

* A Grammar Interpreter
:PROPERTIES:
:TS:       <2016-04-15 10:52AM>
:ID:       7zli6i3147h0
:END:

Our goal is to bootstrap an interpreter for a new programming language.
We would like to build it incrementally from the ground up.

Rather than writing a parser by hand, we would like to model the language syntax and semantics as data, and pass this data to a generic /grammar interpreter/.

We will build the grammar interpreter incrementally, with test cases.

For starters, we will focus on simple regular expressions:, much like python's built-in =re= module.

#+name: @doctests.matcher
#+begin_src python
>>> m = Matcher(Alt([Lit("x"), Lit("y"))   # match the letter x or y, like re.compile("x|y")
>>> m.match("xyz")                         # should match "x" at position 0 
Match(txt="x", pos=0)
>>> m.match("zyx")                         # should fail to match
FAIL
#+end_src

Obviously, the nice syntax provided by the =re= module is nicer than building pattern structures by hand. We will address this soon by bootstrapping our own parser for patterns. In the meantime, we will build our rule definitions by building data structures with python's =namedtuple=.

* Grammar Combinators
:PROPERTIES:
:TS:       <2015-01-18 07:56AM>
:ID:       9906u111jqg0
:END:

Here are our data types for modeling grammar definitions. Since we are using =namedtuple=, there is no actual behavior associated with them. They're just constructors we can manually compose to create data structures.

#+name: @imports
#+begin_src python :session :results none
  from collections import namedtuple
#+end_src
#+name: @code
#+begin_src python :session :results none
  def T(tag, doc, args):
      """Creates a new tuple type."""
      res = namedtuple(tag, args)
      if doc: res.__doc__+=' : '+doc
      return res

  def TB(tag, doc, args=['body']): return T(tag, doc, args)
  def TI(tag, doc, args=['item']): return T(tag, doc, args)
  def TN(tag, doc, args=['name']): return T(tag, doc, args)
  def T2(tag, doc, args=['name','body']): return T(tag, doc, args)

  Gram = T('Gram', 'contains grammar rules (may inherit from `base`).',
           ['name', 'base', 'doc', 'body'])
  Def = T('Def', 'define a named rule.', ['name','body'])
  Ref = TN('Ref', 'refer to (invoke) a named rule')

  Any = T('Any', 'match anything', [])
  Not = TI('Not', 'fail if the pattern would match, but do not consume')
  Skip = TI('Skip', 'match the pattern, but hide it from other rules')

  Lit = TI('Lit', 'match literal item (using ==)')
  Seq = TB('Seq', 'match a sequence of patterns')
  Grp = TB('Grp', 'same as Seq, but renders in parentheses')
  Alt = TB('Alt', 'match any of the alternatives')
  Rep = TI('Rep', 'match 1 or more repetitions.')
  Opt = TI('Opt', 'match 0 or 1 repetitions.')
  Orp = TI('Orp', 'match 0 or more repetitions.')

  Var = T2('Var', 'save matched string in a variable.')
  Val = TN('Val', 'match against the saved value.')
  New = T2('New', 'build a new class/tuple instance')
  Arg = TB('Arg', 'pass matched data as arg to containing "New"')

#+end_src

* Generic dispatch
:PROPERTIES:
:TS:       <2015-01-18 11:36AM>
:ID:       w0bhd8b1jqg0
:END:

Since we will be composing instances of these types into trees, and want our system to interpret the types differently, we need a way to map each type to an appropriate handler.

We will imlement this using a base class that simply maps each =namedtuple= type to a method with the same name (and a given prefix).

In other words, when we see an =Alt= node in the tree, we can use this to automatically invoke a method in our interpreter class called =match_Alt=.

#+name: @imports
#+begin_src python :sesson :results none
from warnings import warn
#+end_src

#+name: @code
#+begin_src python :session :results none

  def node_type(node):
      return node.__class__.__name__

  class Dispatcher(object):
      """Provides a simple generic dispatch mechanism based on method names"""

      def _find_handler(self, prefix, node):
          """(prefix, namedtuple) -> callable"""
          return getattr(self, '_'.join([prefix, node_type(node)]), self._unhandled)

      def _unhandled(self, node, *a, **kw):
          """Warn about unrecognized node types. (Just for development.)"""
          raise ValueError("no handler found for %s" % node_type(node))

      def dispatch(self, prefix, node, *a, **kw):
          """Find and invoke a handler for the given node."""
          h = self._find_handler(prefix, node)
          return h(node, *a, **kw)

#+end_src

* Input cursor
:PROPERTIES:
:TS:       <2015-01-22 05:51AM>
:ID:       m3udu291oqg0
:END:

We also need to keep track of where we are in the input sequence.
The following helper class will do the work for us:

#+name: @code
#+begin_src python :session :results none

  class Cursor(object):

      def __init__(self, seq:[any]):
          self.seq = seq    # sequence (probably a string)
          self.val = None   # current value
          self.pos = -1     # current position
          self.fwd()

      def fwd(self)->any:
          """Move forward in the sequence and return the next item."""
          end = len(self.seq)
          self.pos = min(self.pos+1, end)
          self.val = None if self.pos == end else self.seq[self.pos] 
          return self

#+end_src

* Data structure for parse results.
:PROPERTIES:
:TS:       <2015-01-22 05:58AM>
:ID:       x88gff91oqg0
:END:

Matching should either produce:

... A match object, which stores the matched text, and its position within the input:

#+name: @code
#+begin_src python :session :results none

  Match = namedtuple("Match", ['txt', 'pos'])
  Match.__doc__ = "Match Result"

#+end_src

... Or, a special constant called =FAIL=:

#+name: @code
#+begin_src python :session :results none
  class Fail(object):
      """Value to indicate failure."""
      def __repr__(self):
          return "FAIL"
  FAIL = Fail()
#+end_src

We are also going to use a namedtuple to represent the match state at any given time.
This state includes the match result, a cursor marking the position in the string, and an environment (which we will use later on for storing state). 

#+name: @code
#+begin_src python :session :results none

  class M(namedtuple("M", ['val', 'cur', 'env'])):
      """Internal Match State"""

      @property
      def matched(self):
          return self.val is not FAIL

#+end_src


* Simple pattern matching.
:PROPERTIES:
:TS:       <2016-04-15 11:15AM>
:ID:       yba9ij4147h0
:END:

Now we can start building the matcher. First we will set up the =Dispatch= stuff:  

#+name: @code
#+begin_src python :session :results none

  class Matcher(Dispatcher):
      """A simple matcher for regular languages."""

      def __init__(self, node):
          self.root = node

      def _match(self, node, cur, env):
          """returns a match state tuple (the `M` class)"""
          return self.dispatch('match', node, cur, env)

      def match(self, s:str):
          cur = Cursor(s)
          env = {}
          return self._match(self.root, cur, env).val

#+end_src

Now we are ready to implement the handlers for our initial example:

The simplest case is comparison against a single literal character (=Lit=):

#+name: @code
#+begin_src python :session :results none

  # class Matcher:

      def match_Lit(self, node, cur, env):
          return (M(Match(cur.val, cur.pos), cur.fwd(), env) if cur.val == node.item
                  else M(FAIL, cur, env))
#+end_src


For =Alt=, we just try matching each alternative, in sequence.

Note that only the /first/ matching pattern is returned.

#+name: @code
#+begin_src python :session :results none

  # class Matcher:

      def match_Alt(self, node, cur, env):
          for item in node.body:
              m = self._match(item, cur, env)
              if m.matched: return m
          return m # last failure

#+end_src

At this point, our original example using =Alt([ Lit('x'), Lit('y') ])= works as advertised.

* TODO ---- finish cleaning up everything after this point ---
:PROPERTIES:
:TS:       <2016-04-15 02:43PM>
:ID:       9u58i7e147h0
:END:


#+name: @code
#+begin_src python :session :results none

  # class Matcher:

      def match_Seq(self, node):
          pass

      def match_Rep(self, node):
          pass

      def match_Opt(self, node):
          pass

      def match_Orp(self, node):
          pass

#+end_src





* Strategy
:PROPERTIES:
:TS:       <2015-01-18 10:25AM>
:ID:       nrogjy71jqg0
:END:

The idea here is to manually construct a data structure (an abstract syntax tree) that describes a meta-grammar.

The meta-grammar describes whatever nice clean syntax we'd /like/ to use for creating grammars in the future.

Building these trees by hand can get messy, though, so we'll stick with a simple syntax for this first round, and then use /that/ to implement something better later.

Our first step is to define some types that we can use to tag the different parts of the tree. Each type represents the some feature of our pattern matching system.

* Manually build a base grammar to provide generic tokenization.
:PROPERTIES:
:TS:       <2015-01-18 10:10AM>
:ID:       9d0f2971jqg0
:END:
#+name: @imports
#+begin_src python :session :results none
  import string
#+end_src
#+name: @code
#+begin_src python :session :results none
  ECHR, SQ, DQ = ['\\', "'", '"']
  base = Gram('ebnf', [], "rules common to all grammars", [
      Def('main', Orp('token')),
      Def('token',Seq([Skip(Orp(Ref('space'))),
                    Alt([Ref('STRING'), Ref('NUMBER'),
                         Ref('IDENT'), Ref('DELIM'),
                         Rep(Not(Ref('space')))])])),
      Def('space', Orp('White')),
      # character classes:
      Def('White', Alt([chr(c) for c in range(33)])),
      Def('Upper', Alt(list(string.ascii_uppercase))),
      Def('Lower', Alt(list(string.ascii_lowercase))),
      Def('Alpha', Alt([Ref('Lower'), Ref('Upper')])),
      Def('Under', Lit('_')),
      Def('Neg', Lit('-')),
      Def('Digit', Alt([Lit(c) for c in string.digits])),
      Def('Hexit', Alt([Ref('Digit')]+[Lit(c) for c in 'abcdefABCDEF'])),
      Def('Alnum', Alt([Ref('Under'), Ref('Alpha'), Ref('Digit')])),
      # simple patterns:
      Def('IDENT', Seq([Alt([Ref('Under'),Ref('Alpha')]), Orp(Ref('Alnum'))])),
      Def('NUMBER',Seq([Opt(Ref('Neg')), Rep(Ref('Digit')),
                     Orp([Ref('Under'),
                          Ref('Digit'),Ref('Digit'),Ref('Digit')])])),
      Def('STRING', Alt([Seq([Lit(DQ), Rep(Ref('STRCHR')), Lit(DQ)])])),
      Def('STRCHR', Alt([Seq([Lit(ECHR), Alt([ Lit(ECHR), Lit(DQ) ])]),
                         Not(DQ) ])),
      Def('DELIM', Alt(list('(){}[]'))),
  ])
#+end_src

* Now define the bootstrap grammar to parse EBNF grammar definitions.
:PROPERTIES:
:TS:       <2015-01-18 08:27AM>
:ID:       7o9j7i21jqg0
:END:

#+name: @code
#+begin_src python :session :results none
  ebnf = Gram('ebnf', [base], "ebnf meta-grammar (for parsing grammars)", [
      Def('main', Orp(Ref('rule'))),
      Def('rule', Seq([Var('name', Ref('IDENT')),
                       Lit('='), Ref('expr'), Lit('.') ])),
      Def('expr', Seq([ Ref('term'), Orp([Lit('|'), Ref('term') ]) ])),
      Def('term', Seq([ Ref('factor'), Rep(Ref('factor')) ])),
      Def('factor', Alt([Ref('IDENT'), Ref('STRING'),
                         Ref('rep'), Ref('opt'), Ref('grp')])),
      Def('rep', Seq([Lit('{'), New(Rep, Ref('expr')), Lit('}')])),  # 'x*'
      Def('opt', Seq([Lit('['), New(Opt, Ref('expr')), Lit(']')])),  # 'x?'
      Def('grp', Seq([Lit('('), New(Grp, Ref('expr')), Lit(')')])),  # '(x)'
  ])
#+end_src

* Worlds for backtracking.
:PROPERTIES:
:TS:       <2015-01-18 12:59PM>
:ID:       u8s6vh00kqg0
:END:

A world is a context for holding changes, similar to a working copy in a version control system. The idea is that any time we might need to backtrack (any time an =Alt= node is encountered), we'll fork a new world, and changes we make are done to the world object. This way, if the match ultimately fails, we can rewind the side effects.

This ability is common in prototype-based langugaes like Self and JavaScript (though it isn't necessarily commonly /used/). The name 'World' and the idea of applying it to parsing comes from Alex Warth's [[http://www.tinlizzie.org/ometa/][OMeta]] dissertation.

It's easy to make a python class that works this way: we just override =__getattr__= (for the =x.a= syntax), and =__getitem__= (for the =x[a]= syntax) so that they delegate to a prototype object when there's no local value defined.

Since we do /not/ override the corresponding =__setitem__= and =__setattr__= methods, any assignment made to an attribute or item of the world will affect the local object, leaving the prototype's value unchanged.

It's very much like what happens when overriding methods in a subclass, except it happens for individual objects rather than classes, and it happens dynamically at runtime.

#+name: @code
#+begin_src python :session :results none

  HOME = {} # arbitrary dictionary object

  class World(dict):

      def __init__(self, proto=HOME):
          super(World, self).__init__()
          self.proto = proto

      def __getattr__(self, name):
          # called when attribute has no local definition.
          return getattr(self.proto, name)

      def __getitem__(self, key):
          if key in self.keys(): return super(World, self)[key]
          else: return self.proto[key]

      def changed(self, key, val):
          """Forks a new world, with one key changed."""
          res = World(self)
          res[key] = val
          return res

#+end_src

* Grammar Interpreter
:PROPERTIES:
:TS:       <2015-01-18 12:28PM>
:ID:       n0pcnnd1jqg0
:END:

We will assume for now that we have the entire string in memory.

#+name: @code
#+begin_src python :session :results none

  class Grin(Dispatcher):
      """Grammar Interpreter"""

      def __init__(self, root):
          super(Grin,self).__init__(root)
          self.init(root)

      def parse(self, src):
          self.env = World()
          self.src, self.pos, self.ch = src, 0, ''
          self.page, self.line, self.col = 0, 0, 0

      <<@methods>>
#+end_src

* ebnf in ebnf
:PROPERTIES:
:TS:       <2015-01-18 12:51PM>
:ID:       bd6hv400kqg0
:END:
Here's an grammar for EBNF written in EBNF, so we can test the parser.

This text is adapted from [[http://www.inf.ethz.ch/personal/wirth/CompilerConstruction/index.html][Compiler Construction]] by Niklaus Wirth (who invented EBNF, as well as Pascal, Modula, Oberon, and a variety of other languages).

#+name: ebnf
#+begin_src prolog
main = { rule } .
rule = IDENT "=" expr "." .
expr = term { "|" term } .
term = factor { factor } .
factor = IDENT | STRING | "{" expr "}" | "[" expr "]" | "(" expr ")" .
#+end_src

I placed that code in a block of its own so it would be syntax highlighted, but for python it should be inside a string.

#+name: @code
#+begin_src python :session :results none
ebnf_src = '''\
<<ebnf>>
'''
#+end_src

* OUTPUT wejalboot.py
:PROPERTIES:
:TS:       <2015-01-18 12:38PM>
:ID:       npdbb4e1jqg0
:END:

And now we can put the whole thing together:

#+begin_src python :session :tangle "wejalboot.py" :noweb yes
  <<@imports>>
  <<@code>>
  if __name__=="__main__":
      print(Grin(ebnf).parse(ebnf_src))
#+end_src

If we try to run this now, here's what we'll get:

#+begin_src org
=wejalboot.py:92:= *UserWarning: no handler for init_Gram*
  ~yield warn('no handler for tag: %s' % node.__class__.__name__)~
/None/
#+end_src

So now our job is to go back and fill in a handler method for each node until it's able to walk the whole tree.

* Inference Rules
:PROPERTIES:
:TS:       <2015-01-22 06:01AM>
:ID:       yg99mk91oqg0
:END:

These were translated from the sequent notation in Warth's Ometa paper.

#+name: @methods
#+begin_src python :session :results none

  # (inside  `class Grin`...)

  def match_Ref(self, node, cur, env):
      # pass in fresh World, then discard changes
      tup = self.match(self.defs[node.name], cur, World())
      if tup[0] is FAIL: return (FAIL, env)
      else: return (tup[0], tup[1], env)

  def match_Emp(self, node, cur, env):
      return (None, cur, env)

  def match_Seq(self, node, cur, env):
      for item in node.body:
          tup = self.match(item, cur, env)
          if tup[0] is FAIL: return (FAIL, tup[1])
          else: val, cur, env = tup
      return tup # last value

  def match_Orp(self, node, cur, env):
      vals = []
      while True:
          tup = self.match(node.item, cur, env)
          if tup[0] is FAIL: break
          else:
              val, cur, env = tup
              vals.append(val)
      return (vals, cur, env)

  def match_Not(self, node, cur, env):
      tup = self.match(node.item, cur, env)
      if tup[0] is FAIL: return (None, cur, tup[1])
      else: return (FAIL, tup[1])

  def match_Var(self, node, cur, env):
      tup = self.match(node.item, cur, env)
      if tup[0] is FAIL: return tup
      else: return (tup[0], cur, env.changed(node.name, tup[0]))

  def match_Act(self, node, cur, env):
      raise NotImplementedError('no semantic actions yet.')

  def match_Box(self, node, cur, env):
      raise NotImplementedError('no tree matching yet.')

#+end_src

* Compilation step.
:PROPERTIES:
:TS:       <2015-01-18 02:10PM>
:ID:       ks01bt30kqg0
:END:

#+name: @methods
#+begin_src python :session :results none

  # (still inside  `class Grin`...)
  def init(self, node):
      return self.dispatch('init', node)

  def init_Gram(self, node):
      self.defs = {}
      for child in node.body: self.init(child)

  def init_Def(self, node):
      self.defs[node.name] = node

#+end_src

* TODO credits
:PROPERTIES:
:TS:       <2015-01-22 08:13AM>
:ID:       hnv0l310pqg0
:END:
- grammar rules are adapted from Alessandro Warth's [[http://tinlizzie.org/ometa/][Ometa]] system.
